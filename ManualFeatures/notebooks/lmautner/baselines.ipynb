{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Imports & Preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import torch\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "on_cluster = False"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(1, '/cluster/home/lmautner/music-classification-DL22/' if on_cluster else '/home/lmautner/music-classification-DL22/')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from src.datamodules.components.musical_features_dataset import MusicalFeaturesDataset\n",
    "\n",
    "\n",
    "def read_data(data_dir: str) -> List[MusicalFeaturesDataset]:\n",
    "    features = pd.read_csv(f'{data_dir}/fma_metadata/features.csv', index_col=0, header=[0, 1, 2])\n",
    "\n",
    "    tracks = pd.read_csv(f'{data_dir}/fma_metadata/tracks.csv', index_col=0, header=[0, 1])\n",
    "    tracks['track', 'genre_top'] = tracks['track', 'genre_top'].astype('category')\n",
    "    tracks = tracks[[('track', 'genre_top'), ('set', 'split')]].dropna()\n",
    "\n",
    "    features = features.loc[[idx for idx in features.index if idx in tracks.index]]\n",
    "    tracks = tracks.loc[[idx for idx in tracks.index if idx in features.index]]\n",
    "\n",
    "    features = features.sort_index()\n",
    "    tracks = tracks.sort_index()\n",
    "\n",
    "    index_train = tracks.index[(tracks['set', 'split'] == 'training') | (tracks['set', 'split'] == 'validation')]\n",
    "    index_test = tracks.index[(tracks['set', 'split'] == 'test')]\n",
    "\n",
    "    datasets = []\n",
    "    for idx in [index_train, index_test]:\n",
    "        tracks_idx = tracks.loc[idx, :]\n",
    "        features_idx = features.loc[idx, :]\n",
    "\n",
    "        tracks_idx = tracks_idx[[('track', 'genre_top')]]\n",
    "        labels = np.array(tracks_idx).ravel()\n",
    "        enc = LabelEncoder()\n",
    "        labels = torch.tensor(enc.fit_transform(labels))\n",
    "\n",
    "        feats = np.array(features_idx)\n",
    "        scaler = StandardScaler(copy=False)\n",
    "        feats = torch.tensor(scaler.fit_transform(feats), dtype=torch.float32)\n",
    "\n",
    "        datasets.append(MusicalFeaturesDataset(\n",
    "            features=feats,\n",
    "            genres=labels\n",
    "        ))\n",
    "\n",
    "    return datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "data_dir = '/cluster/scratch/lmautner/mgr/data' if on_cluster else '../../data'\n",
    "\n",
    "dataset_train, dataset_test = read_data(data_dir)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "X_train = dataset_train.features\n",
    "y_train = dataset_train.genres\n",
    "X_test = dataset_test.features\n",
    "y_test = dataset_test.genres"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Definition"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "svc_rbf = SVC(kernel='rbf') if on_cluster else LogisticRegression()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "dimensions = [10, 50, 100, 200, 400, 518]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reduction Baselines"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "results_dir = '/cluster/scratch/lmautner/mgr/results' if on_cluster else '../../data/results'\n",
    "\n",
    "\n",
    "def measure_performance(dir_name: str, preparation_method, preprocessing_method):\n",
    "    scores = []\n",
    "    times_preprocess = []\n",
    "    times_classify = []\n",
    "    times = []\n",
    "\n",
    "    t_prep = time.time()\n",
    "    prep_result = preparation_method()\n",
    "    time_prepare = time.time() - t_prep\n",
    "\n",
    "    for dim in dimensions:\n",
    "        svc = sklearn.base.clone(svc_rbf)\n",
    "\n",
    "        t_start = time.time()\n",
    "\n",
    "        Xtr, Xte = preprocessing_method(prep_result, dim)\n",
    "\n",
    "        t_ready = time.time()\n",
    "\n",
    "        svc.fit(X=Xtr, y=y_train)\n",
    "        scores.append(svc.score(Xte, y_test))\n",
    "\n",
    "        t_end = time.time()\n",
    "\n",
    "        times_preprocess.append(t_ready - t_start)\n",
    "        times_classify.append(t_end - t_ready)\n",
    "        times.append(t_end - t_start)\n",
    "\n",
    "    scores_df = pd.DataFrame(scores, index=dimensions, columns=['score'])\n",
    "    times_preprocess_df = pd.DataFrame(times_preprocess, index=dimensions, columns=['time pre-process (sec)'])\n",
    "    times_classify_df = pd.DataFrame(times_classify, index=dimensions, columns=['time classify (sec)'])\n",
    "    time_prepare_df = pd.DataFrame([time_prepare], index=[0], columns=['time prepare (sec)'])\n",
    "\n",
    "    times_df = pd.DataFrame(times, index=dimensions, columns=['time (sec)'])\n",
    "    times_df['time (sec)'] = times_df['time (sec)'] + time_prepare\n",
    "\n",
    "    path = f'{results_dir}/{dir_name}'\n",
    "    if not os.path.exists(path):\n",
    "            os.mkdir(path)\n",
    "\n",
    "    scores_df.to_csv(f'{path}/scores.csv')\n",
    "    times_preprocess_df.to_csv(f'{path}/times_preprocess.csv')\n",
    "    times_classify_df.to_csv(f'{path}/times_classify.csv')\n",
    "    time_prepare_df.to_csv(f'{path}/time_prepare.csv')\n",
    "    times_df.to_csv(f'{path}/times.csv')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[ 7  7  7 ... 13 13 13].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 14\u001B[0m\n\u001B[1;32m     10\u001B[0m     svd\u001B[38;5;241m.\u001B[39mfit(X_train)\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m svd\u001B[38;5;241m.\u001B[39mtransform(X_train), svd\u001B[38;5;241m.\u001B[39mtransform(X_test)\n\u001B[0;32m---> 14\u001B[0m \u001B[43mmeasure_performance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdir_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msvd\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreparation_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprepare_svd\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreprocessing_method\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreprocess_svd\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[9], line 19\u001B[0m, in \u001B[0;36mmeasure_performance\u001B[0;34m(dir_name, preparation_method, preprocessing_method)\u001B[0m\n\u001B[1;32m     15\u001B[0m svc \u001B[38;5;241m=\u001B[39m sklearn\u001B[38;5;241m.\u001B[39mbase\u001B[38;5;241m.\u001B[39mclone(svc_rbf)\n\u001B[1;32m     17\u001B[0m t_start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m---> 19\u001B[0m Xtr, Xte \u001B[38;5;241m=\u001B[39m \u001B[43mpreprocessing_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep_result\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m t_ready \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m     23\u001B[0m svc\u001B[38;5;241m.\u001B[39mfit(X\u001B[38;5;241m=\u001B[39mXtr, y\u001B[38;5;241m=\u001B[39my_train)\n",
      "Cell \u001B[0;32mIn[10], line 11\u001B[0m, in \u001B[0;36mpreprocess_svd\u001B[0;34m(prep_res, dim)\u001B[0m\n\u001B[1;32m      9\u001B[0m svd \u001B[38;5;241m=\u001B[39m TruncatedSVD(n_components\u001B[38;5;241m=\u001B[39mdim)\n\u001B[1;32m     10\u001B[0m svd\u001B[38;5;241m.\u001B[39mfit(X_train)\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m svd\u001B[38;5;241m.\u001B[39mtransform(X_train), \u001B[43msvd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/music-classification-DL22/venv-music/lib/python3.9/site-packages/sklearn/utils/_set_output.py:142\u001B[0m, in \u001B[0;36m_wrap_method_output.<locals>.wrapped\u001B[0;34m(self, X, *args, **kwargs)\u001B[0m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(f)\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 142\u001B[0m     data_to_wrap \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    143\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_to_wrap, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[1;32m    144\u001B[0m         \u001B[38;5;66;03m# only wrap the first output for cross decomposition\u001B[39;00m\n\u001B[1;32m    145\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[1;32m    146\u001B[0m             _wrap_data_with_container(method, data_to_wrap[\u001B[38;5;241m0\u001B[39m], X, \u001B[38;5;28mself\u001B[39m),\n\u001B[1;32m    147\u001B[0m             \u001B[38;5;241m*\u001B[39mdata_to_wrap[\u001B[38;5;241m1\u001B[39m:],\n\u001B[1;32m    148\u001B[0m         )\n",
      "File \u001B[0;32m~/music-classification-DL22/venv-music/lib/python3.9/site-packages/sklearn/decomposition/_truncated_svd.py:287\u001B[0m, in \u001B[0;36mTruncatedSVD.transform\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    274\u001B[0m \u001B[38;5;124;03m\"\"\"Perform dimensionality reduction on X.\u001B[39;00m\n\u001B[1;32m    275\u001B[0m \n\u001B[1;32m    276\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;124;03m    Reduced version of X. This will always be a dense array.\u001B[39;00m\n\u001B[1;32m    285\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    286\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m--> 287\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    288\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m safe_sparse_dot(X, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcomponents_\u001B[38;5;241m.\u001B[39mT)\n",
      "File \u001B[0;32m~/music-classification-DL22/venv-music/lib/python3.9/site-packages/sklearn/base.py:535\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    533\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mValidation should be done on X, y or both.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    534\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m no_val_y:\n\u001B[0;32m--> 535\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    536\u001B[0m     out \u001B[38;5;241m=\u001B[39m X\n\u001B[1;32m    537\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_y:\n",
      "File \u001B[0;32m~/music-classification-DL22/venv-music/lib/python3.9/site-packages/sklearn/utils/validation.py:900\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    898\u001B[0m     \u001B[38;5;66;03m# If input is 1D raise error\u001B[39;00m\n\u001B[1;32m    899\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m array\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 900\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    901\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected 2D array, got 1D array instead:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124marray=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    902\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    903\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myour data has a single feature or array.reshape(1, -1) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    904\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mif it contains a single sample.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(array)\n\u001B[1;32m    905\u001B[0m         )\n\u001B[1;32m    907\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype_numeric \u001B[38;5;129;01mand\u001B[39;00m array\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mkind \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUSV\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    908\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    909\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumeric\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is not compatible with arrays of bytes/strings.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    910\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConvert your data to numeric values explicitly instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    911\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Expected 2D array, got 1D array instead:\narray=[ 7  7  7 ... 13 13 13].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "\n",
    "def prepare_svd():\n",
    "    return None\n",
    "\n",
    "\n",
    "def preprocess_svd(prep_res, dim):\n",
    "    svd = TruncatedSVD(n_components=dim)\n",
    "    svd.fit(X_train)\n",
    "    return svd.transform(X_train), svd.transform(X_test)\n",
    "\n",
    "\n",
    "measure_performance(dir_name='svd', preparation_method=prepare_svd, preprocessing_method=preprocess_svd)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Random Forest Importance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "def prepare_random_forest():\n",
    "    forest = RandomForestClassifier(random_state=42)\n",
    "    forest.fit(X_train, y_train)\n",
    "\n",
    "    important_feature_indices = np.argsort(forest.feature_importances_)[::-1]\n",
    "    return important_feature_indices\n",
    "\n",
    "\n",
    "def preprocess_random_forest(prep_res, dim):\n",
    "    important_feature_indices = prep_res.copy()[:dim]  # taking the first dim of the importance-sorted features\n",
    "    return X_train[:, important_feature_indices], X_test[:, important_feature_indices]\n",
    "\n",
    "\n",
    "measure_performance(dir_name='random_forest', preparation_method=prepare_random_forest, preprocessing_method=preprocess_random_forest)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Single-Feature Predictiveness"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cutoff_size_train = X_train.shape[0] if on_cluster else 100\n",
    "cutoff_size_test = X_test.shape[0] if on_cluster else 100\n",
    "\n",
    "def prepare_single_feature():\n",
    "    single_feature_scores = []\n",
    "    for fi in range(X_train.shape[1]):\n",
    "        svc_single = sklearn.base.clone(svc_rbf)\n",
    "\n",
    "        f_train = X_train[:cutoff_size_train, [fi]]\n",
    "        f_test = X_test[:cutoff_size_test, [fi]]\n",
    "\n",
    "        svc_single.fit(f_train, y_train[:cutoff_size_train])\n",
    "        single_feature_scores.append(svc_single.score(f_test, y_test[:cutoff_size_test]))\n",
    "\n",
    "    return np.argsort(np.array(single_feature_scores))[::-1]\n",
    "\n",
    "\n",
    "def preprocess_single_feature(prep_res, dim):\n",
    "    important_feature_indices = prep_res.copy()[:dim]  # taking the first dim of the importance-sorted single features\n",
    "    return X_train[:, important_feature_indices], X_test[:, important_feature_indices]\n",
    "\n",
    "\n",
    "measure_performance(dir_name='single_feature', preparation_method=prepare_single_feature, preprocessing_method=preprocess_single_feature)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!../conversion.sh ./baselines.ipynb"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
